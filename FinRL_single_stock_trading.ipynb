{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0-0bsNMMTnSZ",
    "outputId": "e1c336ac-1280-4b16-b1d4-c2971d6667c2"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./FinRL-Library\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "from finrl.config import config\n",
    "from finrl.marketdata.yahoodownloader import YahooDownloader\n",
    "from finrl.preprocessing.preprocessors import FeatureEngineer\n",
    "from finrl.preprocessing.data import data_split\n",
    "from finrl.env.env_stocktrading import StockTradingEnv\n",
    "from finrl.model.models import DRLAgent\n",
    "from datetime import datetime,timedelta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pos2IZAL54pp"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "zp6lL6dZ53rX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JtIFikNyTnSg",
    "outputId": "4c6a860f-6944-4728-984d-d0dc8d8f2c78"
   },
   "outputs": [],
   "source": [
    "col_names=['open','high','low','close']\n",
    "data_df = pd.read_csv('training.csv',names=col_names)\n",
    "data_df['tic']='IBM'\n",
    "base=datetime.strptime(config.START_DATE,\"%Y-%m-%d\")\n",
    "date=[base + timedelta(days=x)for x in range(len(data_df))]\n",
    "data_df['date']=date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "Vi6D_ED6TnSs",
    "outputId": "2313cd51-596f-4a58-922b-5ec837bbcbda"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     open    high     low   close  tic       date\n",
       "0  186.73  188.71  186.00  186.30  IBM 1990-01-01\n",
       "1  185.57  186.33  184.94  185.54  IBM 1990-01-02\n",
       "2  184.81  185.03  183.10  184.66  IBM 1990-01-03\n",
       "3  184.39  184.48  182.31  182.54  IBM 1990-01-04\n",
       "4  182.20  182.27  180.27  181.59  IBM 1990-01-05"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>tic</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>186.73</td>\n      <td>188.71</td>\n      <td>186.00</td>\n      <td>186.30</td>\n      <td>IBM</td>\n      <td>1990-01-01</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>185.57</td>\n      <td>186.33</td>\n      <td>184.94</td>\n      <td>185.54</td>\n      <td>IBM</td>\n      <td>1990-01-02</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>184.81</td>\n      <td>185.03</td>\n      <td>183.10</td>\n      <td>184.66</td>\n      <td>IBM</td>\n      <td>1990-01-03</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>184.39</td>\n      <td>184.48</td>\n      <td>182.31</td>\n      <td>182.54</td>\n      <td>IBM</td>\n      <td>1990-01-04</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>182.20</td>\n      <td>182.27</td>\n      <td>180.27</td>\n      <td>181.59</td>\n      <td>IBM</td>\n      <td>1990-01-05</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rImfGAfCkR8j",
    "outputId": "5b55c2c7-3217-49ad-95b7-d9af0ad91d7a"
   },
   "outputs": [],
   "source": [
    "## user can add more technical indicators\n",
    "## check https://github.com/jealous/stockstats for different names\n",
    "#tech_indicator_list=config.TECHNICAL_INDICATORS_LIST\n",
    "tech_indicator_list=['macd','macds','macdh','kdjk','kdjd','close_5_sma','close_10_sma','close_20_sma','close_60_sma']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etvRo2rSwZPg"
   },
   "source": [
    "<a id='3.2'></a>\n",
    "## 4.2 Perform Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SAOsx0m-9u2k",
    "outputId": "6238a0f8-e0bb-4468-ec75-ab3381ea09a9"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Successfully added technical indicators\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    tech_indicator_list = tech_indicator_list,\n",
    "                    use_turbulence=False,\n",
    "                    user_defined_feature = False)\n",
    "\n",
    "data_df = fe.preprocess_data(data_df)\n",
    "\n",
    "train=data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "wytX_qwWMHP5",
    "outputId": "8113269b-39a0-462b-80b2-b8664eb27a66"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        open    high     low   close  tic       date      macd     macds  \\\n",
       "1483  151.95  152.20  151.33  151.84  IBM 1994-01-23 -0.021715 -0.040454   \n",
       "1484  152.06  152.49  151.62  151.98  IBM 1994-01-24  0.077940 -0.016775   \n",
       "1485  152.35  152.93  151.70  152.47  IBM 1994-01-25  0.194217  0.025423   \n",
       "1486  152.81  153.61  152.17  153.55  IBM 1994-01-26  0.369258  0.094190   \n",
       "1487  153.65  154.41  153.08  153.97  IBM 1994-01-27  0.535694  0.182491   \n",
       "\n",
       "         macdh       kdjk       kdjd  close_5_sma  close_10_sma  close_20_sma  \\\n",
       "1483  0.018738  77.546456  60.081346      151.008       149.771      151.1415   \n",
       "1484  0.094715  82.323964  67.495552      151.610       150.053      151.0565   \n",
       "1485  0.168793  85.934230  73.641778      152.002       150.460      150.9620   \n",
       "1486  0.275067  90.295488  79.193015      152.322       150.926      150.9365   \n",
       "1487  0.353203  90.901890  83.095973      152.762       151.613      150.9335   \n",
       "\n",
       "      close_60_sma  \n",
       "1483    148.879000  \n",
       "1484    149.028167  \n",
       "1485    149.168000  \n",
       "1486    149.343167  \n",
       "1487    149.512333  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>tic</th>\n      <th>date</th>\n      <th>macd</th>\n      <th>macds</th>\n      <th>macdh</th>\n      <th>kdjk</th>\n      <th>kdjd</th>\n      <th>close_5_sma</th>\n      <th>close_10_sma</th>\n      <th>close_20_sma</th>\n      <th>close_60_sma</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1483</th>\n      <td>151.95</td>\n      <td>152.20</td>\n      <td>151.33</td>\n      <td>151.84</td>\n      <td>IBM</td>\n      <td>1994-01-23</td>\n      <td>-0.021715</td>\n      <td>-0.040454</td>\n      <td>0.018738</td>\n      <td>77.546456</td>\n      <td>60.081346</td>\n      <td>151.008</td>\n      <td>149.771</td>\n      <td>151.1415</td>\n      <td>148.879000</td>\n    </tr>\n    <tr>\n      <th>1484</th>\n      <td>152.06</td>\n      <td>152.49</td>\n      <td>151.62</td>\n      <td>151.98</td>\n      <td>IBM</td>\n      <td>1994-01-24</td>\n      <td>0.077940</td>\n      <td>-0.016775</td>\n      <td>0.094715</td>\n      <td>82.323964</td>\n      <td>67.495552</td>\n      <td>151.610</td>\n      <td>150.053</td>\n      <td>151.0565</td>\n      <td>149.028167</td>\n    </tr>\n    <tr>\n      <th>1485</th>\n      <td>152.35</td>\n      <td>152.93</td>\n      <td>151.70</td>\n      <td>152.47</td>\n      <td>IBM</td>\n      <td>1994-01-25</td>\n      <td>0.194217</td>\n      <td>0.025423</td>\n      <td>0.168793</td>\n      <td>85.934230</td>\n      <td>73.641778</td>\n      <td>152.002</td>\n      <td>150.460</td>\n      <td>150.9620</td>\n      <td>149.168000</td>\n    </tr>\n    <tr>\n      <th>1486</th>\n      <td>152.81</td>\n      <td>153.61</td>\n      <td>152.17</td>\n      <td>153.55</td>\n      <td>IBM</td>\n      <td>1994-01-26</td>\n      <td>0.369258</td>\n      <td>0.094190</td>\n      <td>0.275067</td>\n      <td>90.295488</td>\n      <td>79.193015</td>\n      <td>152.322</td>\n      <td>150.926</td>\n      <td>150.9365</td>\n      <td>149.343167</td>\n    </tr>\n    <tr>\n      <th>1487</th>\n      <td>153.65</td>\n      <td>154.41</td>\n      <td>153.08</td>\n      <td>153.97</td>\n      <td>IBM</td>\n      <td>1994-01-27</td>\n      <td>0.535694</td>\n      <td>0.182491</td>\n      <td>0.353203</td>\n      <td>90.901890</td>\n      <td>83.095973</td>\n      <td>152.762</td>\n      <td>151.613</td>\n      <td>150.9335</td>\n      <td>149.512333</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ipJcnLvQGAba",
    "outputId": "dc32ebc6-2191-4541-99d2-7e9861da5df6"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Stock Dimension: 1, State Space: 12\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = 1\n",
    "state_space = 1 + 2*stock_dimension + len(tech_indicator_list)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "JY5wTwYjGTrg"
   },
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"hmax\": 1, \n",
    "    \"initial_amount\": 100000, \n",
    "    \"buy_cost_pct\": 0, \n",
    "    \"sell_cost_pct\": 0, \n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": tech_indicator_list, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-5\n",
    "\n",
    "}\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vmyi2IPnyEkP",
    "outputId": "a968a96a-a1ee-426e-eed8-ee74d20b9bb8"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))\n",
    "agent = DRLAgent(env = env_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9CM5DeIr9GC"
   },
   "source": [
    "### Model 1: A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rOk-Mr73-EEq",
    "outputId": "1c56a5c6-91ad-4b81-dd07-24ae69e64c23"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nagent = DRLAgent(env = env_train)\\n\\nA2C_PARAMS = {\"n_steps\": 5, \"ent_coef\": 0.005, \"learning_rate\": 0.0002}\\nmodel_a2c = agent.get_model(model_name=\"a2c\",model_kwargs = A2C_PARAMS)\\n\\ntrained_a2c = agent.train_model(model=model_a2c, \\n                                tb_log_name=\\'a2c\\',\\n                                total_timesteps=50000)\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "'''\n",
    "agent = DRLAgent(env = env_train)\n",
    "\n",
    "A2C_PARAMS = {\"n_steps\": 5, \"ent_coef\": 0.005, \"learning_rate\": 0.0002}\n",
    "model_a2c = agent.get_model(model_name=\"a2c\",model_kwargs = A2C_PARAMS)\n",
    "\n",
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                                tb_log_name='a2c',\n",
    "                                total_timesteps=50000)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9upN8FI2r_X1"
   },
   "source": [
    "### Model 2: PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gUFJlHsi-Ka-",
    "outputId": "1b7db70f-f740-401c-ab55-a567b4235e18"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.005, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo/ppo_59\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 9.99e+04 |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | -121     |\n",
      "|    total_reward_pct | -0.121   |\n",
      "|    total_trades     | 316      |\n",
      "| time/               |          |\n",
      "|    fps              | 638      |\n",
      "|    iterations       | 1        |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 2048     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 9.99e+04     |\n",
      "|    total_cost           | 0            |\n",
      "|    total_reward         | -73.9        |\n",
      "|    total_reward_pct     | -0.0739      |\n",
      "|    total_trades         | 308          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 566          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009248616 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0108      |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -7.33e-05    |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 0.000999     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1e+05        |\n",
      "|    total_cost           | 0            |\n",
      "|    total_reward         | 88.8         |\n",
      "|    total_reward_pct     | 0.0888       |\n",
      "|    total_trades         | 323          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 550          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031274692 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00189     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 0.000776     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| environment/            |               |\n",
      "|    portfolio_value      | 9.99e+04      |\n",
      "|    total_cost           | 0             |\n",
      "|    total_reward         | -69.3         |\n",
      "|    total_reward_pct     | -0.0693       |\n",
      "|    total_trades         | 285           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 541           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 15            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.4255764e-05 |\n",
      "|    clip_fraction        | 0.000342      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.42         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | -0.00116      |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -5.99e-05     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.000875      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.99e+04    |\n",
      "|    total_cost           | 0           |\n",
      "|    total_reward         | -54.2       |\n",
      "|    total_reward_pct     | -0.0542     |\n",
      "|    total_trades         | 285         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 539         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008359937 |\n",
      "|    clip_fraction        | 0.0451      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0096     |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0012     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.000339    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1e+05       |\n",
      "|    total_cost           | 0           |\n",
      "|    total_reward         | -34.3       |\n",
      "|    total_reward_pct     | -0.0343     |\n",
      "|    total_trades         | 307         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 541         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012537177 |\n",
      "|    clip_fraction        | 0.0922      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0297     |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00315    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 0.000228    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1e+05        |\n",
      "|    total_cost           | 0            |\n",
      "|    total_reward         | 85.5         |\n",
      "|    total_reward_pct     | 0.0855       |\n",
      "|    total_trades         | 281          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 542          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012867549 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00747     |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.000466    |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 0.00029      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 9.99e+04     |\n",
      "|    total_cost           | 0            |\n",
      "|    total_reward         | -118         |\n",
      "|    total_reward_pct     | -0.118       |\n",
      "|    total_trades         | 248          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 543          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0082826875 |\n",
      "|    clip_fraction        | 0.0573       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00695     |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 0.000117     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1e+05        |\n",
      "|    total_cost           | 0            |\n",
      "|    total_reward         | 70.7         |\n",
      "|    total_reward_pct     | 0.0707       |\n",
      "|    total_trades         | 259          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 544          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 33           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022472225 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00606     |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -4.94e-05    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.000132     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1e+05        |\n",
      "|    total_cost           | 0            |\n",
      "|    total_reward         | -19.7        |\n",
      "|    total_reward_pct     | -0.0197      |\n",
      "|    total_trades         | 304          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 544          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 37           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031074458 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00274     |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.000359    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 5.1e-05      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1e+05       |\n",
      "|    total_cost           | 0           |\n",
      "|    total_reward         | 41.7        |\n",
      "|    total_reward_pct     | 0.0417      |\n",
      "|    total_trades         | 265         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 542         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010125554 |\n",
      "|    clip_fraction        | 0.0348      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00422    |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00155    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 3.65e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1e+05       |\n",
      "|    total_cost           | 0           |\n",
      "|    total_reward         | 46.9        |\n",
      "|    total_reward_pct     | 0.0469      |\n",
      "|    total_trades         | 241         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 543         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008849018 |\n",
      "|    clip_fraction        | 0.0528      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0118     |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00184    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 4.23e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1e+05       |\n",
      "|    total_cost           | 0           |\n",
      "|    total_reward         | 25          |\n",
      "|    total_reward_pct     | 0.025       |\n",
      "|    total_trades         | 272         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 544         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009127555 |\n",
      "|    clip_fraction        | 0.0859      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0175      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00229    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 1.83e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1e+05        |\n",
      "|    total_cost           | 0            |\n",
      "|    total_reward         | 63.1         |\n",
      "|    total_reward_pct     | 0.0631       |\n",
      "|    total_trades         | 235          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 544          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 52           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073581142 |\n",
      "|    clip_fraction        | 0.0587       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.43        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0122      |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00157     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 1.29e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1e+05       |\n",
      "|    total_cost           | 0           |\n",
      "|    total_reward         | 16          |\n",
      "|    total_reward_pct     | 0.016       |\n",
      "|    total_trades         | 213         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 545         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004966424 |\n",
      "|    clip_fraction        | 0.0626      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0148     |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00117    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.22e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.99e+04    |\n",
      "|    total_cost           | 0           |\n",
      "|    total_reward         | -86.7       |\n",
      "|    total_reward_pct     | -0.0867     |\n",
      "|    total_trades         | 168         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 546         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007070725 |\n",
      "|    clip_fraction        | 0.0464      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0167     |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.000869   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 4.94e-06    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| environment/            |               |\n",
      "|    portfolio_value      | 1e+05         |\n",
      "|    total_cost           | 0             |\n",
      "|    total_reward         | -3.56         |\n",
      "|    total_reward_pct     | -0.00356      |\n",
      "|    total_trades         | 187           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 546           |\n",
      "|    iterations           | 17            |\n",
      "|    time_elapsed         | 63            |\n",
      "|    total_timesteps      | 34816         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033545075 |\n",
      "|    clip_fraction        | 0.00391       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.43         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | -0.00369      |\n",
      "|    n_updates            | 160           |\n",
      "|    policy_gradient_loss | -0.000242     |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 6.3e-06       |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1e+05       |\n",
      "|    total_cost           | 0           |\n",
      "|    total_reward         | 36.6        |\n",
      "|    total_reward_pct     | 0.0366      |\n",
      "|    total_trades         | 203         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 547         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003521297 |\n",
      "|    clip_fraction        | 0.0192      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00623    |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00141    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 2.41e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1e+05       |\n",
      "|    total_cost           | 0           |\n",
      "|    total_reward         | 18.3        |\n",
      "|    total_reward_pct     | 0.0183      |\n",
      "|    total_trades         | 153         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 547         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002736763 |\n",
      "|    clip_fraction        | 0.0312      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0122     |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.000984   |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 1.53e-06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1e+05        |\n",
      "|    total_cost           | 0            |\n",
      "|    total_reward         | 73.1         |\n",
      "|    total_reward_pct     | 0.0731       |\n",
      "|    total_trades         | 173          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 547          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 74           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026655572 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.45        |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00214     |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.000495    |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 1.83e-06     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1e+05       |\n",
      "|    total_cost           | 0           |\n",
      "|    total_reward         | -44.8       |\n",
      "|    total_reward_pct     | -0.0448     |\n",
      "|    total_trades         | 161         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 548         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008779331 |\n",
      "|    clip_fraction        | 0.047       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00133    |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00236    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 6.34e-07    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| environment/            |               |\n",
      "|    portfolio_value      | 1e+05         |\n",
      "|    total_cost           | 0             |\n",
      "|    total_reward         | -45.1         |\n",
      "|    total_reward_pct     | -0.0451       |\n",
      "|    total_trades         | 155           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 548           |\n",
      "|    iterations           | 22            |\n",
      "|    time_elapsed         | 82            |\n",
      "|    total_timesteps      | 45056         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00065659394 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.46         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | -0.00861      |\n",
      "|    n_updates            | 210           |\n",
      "|    policy_gradient_loss | -5.14e-05     |\n",
      "|    std                  | 1.04          |\n",
      "|    value_loss           | 5.5e-07       |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| environment/            |            |\n",
      "|    portfolio_value      | 1e+05      |\n",
      "|    total_cost           | 0          |\n",
      "|    total_reward         | -23.3      |\n",
      "|    total_reward_pct     | -0.0233    |\n",
      "|    total_trades         | 111        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 548        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 85         |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00284673 |\n",
      "|    clip_fraction        | 0.0302     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.46      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.00586    |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.00103   |\n",
      "|    std                  | 1.05       |\n",
      "|    value_loss           | 5.79e-07   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1e+05        |\n",
      "|    total_cost           | 0            |\n",
      "|    total_reward         | 25.2         |\n",
      "|    total_reward_pct     | 0.0252       |\n",
      "|    total_trades         | 75           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 545          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 90           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017417833 |\n",
      "|    clip_fraction        | 0.00825      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.47        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0142      |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -2.34e-05    |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 2.99e-07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1e+05        |\n",
      "|    total_cost           | 0            |\n",
      "|    total_reward         | -13.9        |\n",
      "|    total_reward_pct     | -0.0139      |\n",
      "|    total_trades         | 89           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 544          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 93           |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012560708 |\n",
      "|    clip_fraction        | 0.00249      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.47        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00847     |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.000233    |\n",
      "|    std                  | 1.05         |\n",
      "|    value_loss           | 2.99e-07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1e+05       |\n",
      "|    total_cost           | 0           |\n",
      "|    total_reward         | 17.9        |\n",
      "|    total_reward_pct     | 0.0179      |\n",
      "|    total_trades         | 95          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 545         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004867973 |\n",
      "|    clip_fraction        | 0.0319      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0046      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.000836   |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 1.11e-07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1e+05       |\n",
      "|    total_cost           | 0           |\n",
      "|    total_reward         | -44         |\n",
      "|    total_reward_pct     | -0.044      |\n",
      "|    total_trades         | 159         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 545         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010999321 |\n",
      "|    clip_fraction        | 0.0695      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0186     |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00388    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 7e-08       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1e+05       |\n",
      "|    total_cost           | 0           |\n",
      "|    total_reward         | 12.5        |\n",
      "|    total_reward_pct     | 0.0125      |\n",
      "|    total_trades         | 139         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 545         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 105         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006702843 |\n",
      "|    clip_fraction        | 0.0454      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0124     |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00156    |\n",
      "|    std                  | 1.06        |\n",
      "|    value_loss           | 1.19e-07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1e+05        |\n",
      "|    total_cost           | 0            |\n",
      "|    total_reward         | 1            |\n",
      "|    total_reward_pct     | 0.001        |\n",
      "|    total_trades         | 115          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 546          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 108          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021087388 |\n",
      "|    clip_fraction        | 0.00542      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.48        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00561     |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.000419    |\n",
      "|    std                  | 1.07         |\n",
      "|    value_loss           | 4.46e-08     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1e+05       |\n",
      "|    total_cost           | 0           |\n",
      "|    total_reward         | -6.29       |\n",
      "|    total_reward_pct     | -0.00629    |\n",
      "|    total_trades         | 149         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 545         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004316456 |\n",
      "|    clip_fraction        | 0.00229     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00327     |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -9.35e-05   |\n",
      "|    std                  | 1.07        |\n",
      "|    value_loss           | 3.62e-08    |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.005,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n",
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                            tb_log_name='ppo',\n",
    "                            total_timesteps=60000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Successfully added technical indicators\n",
      "    0\n",
      "0   0\n",
      "1   0\n",
      "2  -1\n",
      "3   0\n",
      "4   0\n",
      "5   0\n",
      "6   0\n",
      "7   0\n",
      "8   0\n",
      "9   1\n",
      "10  0\n",
      "11 -1\n",
      "12  0\n",
      "13  0\n",
      "14  0\n",
      "15  0\n",
      "16  1\n",
      "17 -1\n",
      "18  0\n",
      "100001.56000000001\n",
      "10.0%\n"
     ]
    }
   ],
   "source": [
    "trade = pd.read_csv('testing.csv',names=col_names)\n",
    "trade['tic']='IBM'\n",
    "base=datetime.strptime(config.START_TRADE_DATE,\"%Y-%m-%d\")\n",
    "date=[base + timedelta(days=x)for x in range(len(trade))]\n",
    "trade['date']=date\n",
    "trade=fe.preprocess_data(trade)\n",
    "\n",
    "e_trade_gym = StockTradingEnv(df = trade, **env_kwargs)\n",
    "\n",
    "max_profit=0\n",
    "actions=None\n",
    "negative_trade=0\n",
    "total_testing_num=10\n",
    "for _ in range(total_testing_num):\n",
    "    df_account_value, df_actions = DRLAgent.DRL_prediction(model=trained_ppo,environment = e_trade_gym)\n",
    "    final_profit=df_account_value['account_value'].iloc[-1]\n",
    "    if final_profit<100000:\n",
    "        negative_trade+=1\n",
    "    \n",
    "df_account_value, df_actions = DRLAgent.DRL_prediction(model=trained_ppo,environment = e_trade_gym)\n",
    "final_profit=df_account_value['account_value'].iloc[-1]\n",
    "actions=pd.DataFrame(np.array(df_actions['actions'],dtype='int'))\n",
    "print(actions)\n",
    "print(final_profit)\n",
    "print(f\"{(negative_trade/total_testing_num)*100}%\")\n",
    "actions.to_csv(\"output.csv\",index=False,header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Y9CM5DeIr9GC",
    "9upN8FI2r_X1",
    "CiBG2ZknsG73"
   ],
   "include_colab_link": true,
   "name": "FinRL_single_stock_trading.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}