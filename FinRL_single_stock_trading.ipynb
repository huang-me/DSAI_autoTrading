{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0-0bsNMMTnSZ",
    "outputId": "e1c336ac-1280-4b16-b1d4-c2971d6667c2"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./FinRL-Library\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "from finrl.config import config\n",
    "from finrl.marketdata.yahoodownloader import YahooDownloader\n",
    "from finrl.preprocessing.preprocessors import FeatureEngineer\n",
    "from finrl.preprocessing.data import data_split\n",
    "from finrl.env.env_stocktrading import StockTradingEnv\n",
    "from finrl.model.models import DRLAgent\n",
    "from datetime import datetime,timedelta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pos2IZAL54pp"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zp6lL6dZ53rX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JtIFikNyTnSg",
    "outputId": "4c6a860f-6944-4728-984d-d0dc8d8f2c78"
   },
   "outputs": [],
   "source": [
    "col_names=['open','high','low','close']\n",
    "data_df = pd.read_csv('training.csv',names=col_names)\n",
    "data_df['tic']='IBM'\n",
    "base=datetime.strptime(config.START_DATE,\"%Y-%m-%d\")\n",
    "date=[base + timedelta(days=x)for x in range(len(data_df))]\n",
    "data_df['date']=date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "Vi6D_ED6TnSs",
    "outputId": "2313cd51-596f-4a58-922b-5ec837bbcbda"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     open    high     low   close  tic       date\n",
       "0  186.73  188.71  186.00  186.30  IBM 1990-01-01\n",
       "1  185.57  186.33  184.94  185.54  IBM 1990-01-02\n",
       "2  184.81  185.03  183.10  184.66  IBM 1990-01-03\n",
       "3  184.39  184.48  182.31  182.54  IBM 1990-01-04\n",
       "4  182.20  182.27  180.27  181.59  IBM 1990-01-05"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>tic</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>186.73</td>\n      <td>188.71</td>\n      <td>186.00</td>\n      <td>186.30</td>\n      <td>IBM</td>\n      <td>1990-01-01</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>185.57</td>\n      <td>186.33</td>\n      <td>184.94</td>\n      <td>185.54</td>\n      <td>IBM</td>\n      <td>1990-01-02</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>184.81</td>\n      <td>185.03</td>\n      <td>183.10</td>\n      <td>184.66</td>\n      <td>IBM</td>\n      <td>1990-01-03</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>184.39</td>\n      <td>184.48</td>\n      <td>182.31</td>\n      <td>182.54</td>\n      <td>IBM</td>\n      <td>1990-01-04</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>182.20</td>\n      <td>182.27</td>\n      <td>180.27</td>\n      <td>181.59</td>\n      <td>IBM</td>\n      <td>1990-01-05</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rImfGAfCkR8j",
    "outputId": "5b55c2c7-3217-49ad-95b7-d9af0ad91d7a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma', 'kdjk', 'open_2_sma', 'boll', 'close_10.0_le_5_c', 'wr_10', 'dma', 'trix']\n"
     ]
    }
   ],
   "source": [
    "## user can add more technical indicators\n",
    "## check https://github.com/jealous/stockstats for different names\n",
    "tech_indicator_list=config.TECHNICAL_INDICATORS_LIST\n",
    "tech_indicator_list=tech_indicator_list+['kdjk','open_2_sma','boll','close_10.0_le_5_c','wr_10','dma','trix']\n",
    "print(tech_indicator_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etvRo2rSwZPg"
   },
   "source": [
    "<a id='3.2'></a>\n",
    "## 4.2 Perform Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SAOsx0m-9u2k",
    "outputId": "6238a0f8-e0bb-4468-ec75-ab3381ea09a9"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Successfully added technical indicators\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    tech_indicator_list = tech_indicator_list,\n",
    "                    use_turbulence=False,\n",
    "                    user_defined_feature = False)\n",
    "\n",
    "data_df = fe.preprocess_data(data_df)\n",
    "\n",
    "train=data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "wytX_qwWMHP5",
    "outputId": "8113269b-39a0-462b-80b2-b8664eb27a66"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     open    high     low   close  tic       date      macd     boll_ub  \\\n",
       "0  186.73  188.71  186.00  186.30  IBM 1990-01-01  0.000000  186.994802   \n",
       "1  185.57  186.33  184.94  185.54  IBM 1990-01-02 -0.017051  186.994802   \n",
       "2  184.81  185.03  183.10  184.66  IBM 1990-01-03 -0.049015  187.141463   \n",
       "3  184.39  184.48  182.31  182.54  IBM 1990-01-04 -0.138894  188.009287   \n",
       "4  182.20  182.27  180.27  181.59  IBM 1990-01-05 -0.222611  188.120686   \n",
       "\n",
       "      boll_lb  rsi_30  ...  dx_30  close_30_sma  close_60_sma       kdjk  \\\n",
       "0  184.845198     0.0  ...  100.0       186.300       186.300  37.023370   \n",
       "1  184.845198     0.0  ...  100.0       185.920       185.920  29.987287   \n",
       "2  183.858537     0.0  ...  100.0       185.500       185.500  29.260687   \n",
       "3  181.510713     0.0  ...  100.0       184.760       184.760  20.705041   \n",
       "4  180.131314     0.0  ...  100.0       184.126       184.126  19.016631   \n",
       "\n",
       "   open_2_sma     boll  close_10.0_le_5_c      wr_10  dma      trix  \n",
       "0     186.730  186.300                0.0  88.929889  0.0 -0.064833  \n",
       "1     186.150  185.920                0.0  84.084881  0.0 -0.064833  \n",
       "2     185.190  185.500                0.0  72.192513  0.0 -0.076090  \n",
       "3     184.600  184.760                0.0  96.406250  0.0 -0.107870  \n",
       "4     183.295  184.126                0.0  84.360190  0.0 -0.130739  \n",
       "\n",
       "[5 rows x 21 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>tic</th>\n      <th>date</th>\n      <th>macd</th>\n      <th>boll_ub</th>\n      <th>boll_lb</th>\n      <th>rsi_30</th>\n      <th>...</th>\n      <th>dx_30</th>\n      <th>close_30_sma</th>\n      <th>close_60_sma</th>\n      <th>kdjk</th>\n      <th>open_2_sma</th>\n      <th>boll</th>\n      <th>close_10.0_le_5_c</th>\n      <th>wr_10</th>\n      <th>dma</th>\n      <th>trix</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>186.73</td>\n      <td>188.71</td>\n      <td>186.00</td>\n      <td>186.30</td>\n      <td>IBM</td>\n      <td>1990-01-01</td>\n      <td>0.000000</td>\n      <td>186.994802</td>\n      <td>184.845198</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>100.0</td>\n      <td>186.300</td>\n      <td>186.300</td>\n      <td>37.023370</td>\n      <td>186.730</td>\n      <td>186.300</td>\n      <td>0.0</td>\n      <td>88.929889</td>\n      <td>0.0</td>\n      <td>-0.064833</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>185.57</td>\n      <td>186.33</td>\n      <td>184.94</td>\n      <td>185.54</td>\n      <td>IBM</td>\n      <td>1990-01-02</td>\n      <td>-0.017051</td>\n      <td>186.994802</td>\n      <td>184.845198</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>100.0</td>\n      <td>185.920</td>\n      <td>185.920</td>\n      <td>29.987287</td>\n      <td>186.150</td>\n      <td>185.920</td>\n      <td>0.0</td>\n      <td>84.084881</td>\n      <td>0.0</td>\n      <td>-0.064833</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>184.81</td>\n      <td>185.03</td>\n      <td>183.10</td>\n      <td>184.66</td>\n      <td>IBM</td>\n      <td>1990-01-03</td>\n      <td>-0.049015</td>\n      <td>187.141463</td>\n      <td>183.858537</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>100.0</td>\n      <td>185.500</td>\n      <td>185.500</td>\n      <td>29.260687</td>\n      <td>185.190</td>\n      <td>185.500</td>\n      <td>0.0</td>\n      <td>72.192513</td>\n      <td>0.0</td>\n      <td>-0.076090</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>184.39</td>\n      <td>184.48</td>\n      <td>182.31</td>\n      <td>182.54</td>\n      <td>IBM</td>\n      <td>1990-01-04</td>\n      <td>-0.138894</td>\n      <td>188.009287</td>\n      <td>181.510713</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>100.0</td>\n      <td>184.760</td>\n      <td>184.760</td>\n      <td>20.705041</td>\n      <td>184.600</td>\n      <td>184.760</td>\n      <td>0.0</td>\n      <td>96.406250</td>\n      <td>0.0</td>\n      <td>-0.107870</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>182.20</td>\n      <td>182.27</td>\n      <td>180.27</td>\n      <td>181.59</td>\n      <td>IBM</td>\n      <td>1990-01-05</td>\n      <td>-0.222611</td>\n      <td>188.120686</td>\n      <td>180.131314</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>100.0</td>\n      <td>184.126</td>\n      <td>184.126</td>\n      <td>19.016631</td>\n      <td>183.295</td>\n      <td>184.126</td>\n      <td>0.0</td>\n      <td>84.360190</td>\n      <td>0.0</td>\n      <td>-0.130739</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ipJcnLvQGAba",
    "outputId": "dc32ebc6-2191-4541-99d2-7e9861da5df6"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Stock Dimension: 1, State Space: 18\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = 1\n",
    "state_space = 1 + 2*stock_dimension + len(tech_indicator_list)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "JY5wTwYjGTrg"
   },
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"hmax\": 1, \n",
    "    \"initial_amount\": 10000, \n",
    "    \"buy_cost_pct\": 0, \n",
    "    \"sell_cost_pct\": 0, \n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": tech_indicator_list, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4\n",
    "}\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vmyi2IPnyEkP",
    "outputId": "a968a96a-a1ee-426e-eed8-ee74d20b9bb8"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9CM5DeIr9GC"
   },
   "source": [
    "### Model 1: A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rOk-Mr73-EEq",
    "outputId": "1c56a5c6-91ad-4b81-dd07-24ae69e64c23"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0002}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c/a2c_25\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 37        |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 13        |\n",
      "|    total_timesteps    | 500       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.43     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | 5.08e-05  |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2.99e-09  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 68        |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.45     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | -4.69e-05 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 4.55e-09  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.99e+03 |\n",
      "|    total_cost         | 0        |\n",
      "|    total_reward       | -14      |\n",
      "|    total_reward_pct   | -0.14    |\n",
      "|    total_trades       | 318      |\n",
      "| time/                 |          |\n",
      "|    fps                | 94       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.46    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 0.000229 |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 2.14e-08 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 117       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.48     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | -6.09e-05 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 2.43e-08  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 136      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.5     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 0.000291 |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 2.06e-08 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.96e+03  |\n",
      "|    total_cost         | 0         |\n",
      "|    total_reward       | -42       |\n",
      "|    total_reward_pct   | -0.42     |\n",
      "|    total_trades       | 363       |\n",
      "| time/                 |           |\n",
      "|    fps                | 154       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 19        |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.52     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | -0.00095  |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 4.98e-07  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 169       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 20        |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.53     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | 0.000339  |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 4.48e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 182       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 21        |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.54     |\n",
      "|    explained_variance | 0.163     |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | -0.000557 |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 2.9e-07   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.96e+03 |\n",
      "|    total_cost         | 0        |\n",
      "|    total_reward       | -37.8    |\n",
      "|    total_reward_pct   | -0.378   |\n",
      "|    total_trades       | 347      |\n",
      "| time/                 |          |\n",
      "|    fps                | 194      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.56    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 0.000845 |\n",
      "|    std                | 1.15     |\n",
      "|    value_loss         | 5.97e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 205      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.57    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 0.000242 |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 3.42e-08 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 215       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 25        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.59     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | -0.000577 |\n",
      "|    std                | 1.19      |\n",
      "|    value_loss         | 1.97e-07  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.01e+04  |\n",
      "|    total_cost         | 0         |\n",
      "|    total_reward       | 145       |\n",
      "|    total_reward_pct   | 1.45      |\n",
      "|    total_trades       | 370       |\n",
      "| time/                 |           |\n",
      "|    fps                | 224       |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.61     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | 0.000416  |\n",
      "|    std                | 1.21      |\n",
      "|    value_loss         | 4.15e-08  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 232      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.63    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 0.000338 |\n",
      "|    std                | 1.24     |\n",
      "|    value_loss         | 1.03e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 240      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.65    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -0.00329 |\n",
      "|    std                | 1.26     |\n",
      "|    value_loss         | 1.25e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.96e+03  |\n",
      "|    total_cost         | 0         |\n",
      "|    total_reward       | -44.8     |\n",
      "|    total_reward_pct   | -0.448    |\n",
      "|    total_trades       | 453       |\n",
      "| time/                 |           |\n",
      "|    fps                | 247       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 30        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.66     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | -3.08e-05 |\n",
      "|    std                | 1.28      |\n",
      "|    value_loss         | 3.36e-09  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 253      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.68    |\n",
      "|    explained_variance | -45.9    |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 0.00214  |\n",
      "|    std                | 1.3      |\n",
      "|    value_loss         | 1.87e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 259       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 32        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.7      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | -0.000251 |\n",
      "|    std                | 1.33      |\n",
      "|    value_loss         | 5.3e-08   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.96e+03  |\n",
      "|    total_cost         | 0         |\n",
      "|    total_reward       | -36       |\n",
      "|    total_reward_pct   | -0.36     |\n",
      "|    total_trades       | 475       |\n",
      "| time/                 |           |\n",
      "|    fps                | 264       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 33        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.72     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | -0.000388 |\n",
      "|    std                | 1.35      |\n",
      "|    value_loss         | 7.56e-08  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 269      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.74    |\n",
      "|    explained_variance | 5.19e-06 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 0.00929  |\n",
      "|    std                | 1.38     |\n",
      "|    value_loss         | 3.11e-05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.76    |\n",
      "|    explained_variance | -0.0272  |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 0.00118  |\n",
      "|    std                | 1.4      |\n",
      "|    value_loss         | 7.88e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.93e+03 |\n",
      "|    total_cost         | 0        |\n",
      "|    total_reward       | -71.9    |\n",
      "|    total_reward_pct   | -0.719   |\n",
      "|    total_trades       | 455      |\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.78    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -0.00084 |\n",
      "|    std                | 1.43     |\n",
      "|    value_loss         | 2.36e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 279      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.8     |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -0.00108 |\n",
      "|    std                | 1.46     |\n",
      "|    value_loss         | 4.09e-07 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 282       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 40        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.82     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | -0.000215 |\n",
      "|    std                | 1.49      |\n",
      "|    value_loss         | 3.44e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+04     |\n",
      "|    total_cost         | 0         |\n",
      "|    total_reward       | -2.42     |\n",
      "|    total_reward_pct   | -0.0242   |\n",
      "|    total_trades       | 463       |\n",
      "| time/                 |           |\n",
      "|    fps                | 285       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 41        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.83     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | -0.000618 |\n",
      "|    std                | 1.51      |\n",
      "|    value_loss         | 1.33e-07  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 289       |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.85     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | -0.000576 |\n",
      "|    std                | 1.54      |\n",
      "|    value_loss         | 1.08e-07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.87    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 0.000264 |\n",
      "|    std                | 1.57     |\n",
      "|    value_loss         | 3.95e-08 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.96e+03  |\n",
      "|    total_cost         | 0         |\n",
      "|    total_reward       | -38.7     |\n",
      "|    total_reward_pct   | -0.387    |\n",
      "|    total_trades       | 505       |\n",
      "| time/                 |           |\n",
      "|    fps                | 295       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 45        |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.89     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | -0.000462 |\n",
      "|    std                | 1.6       |\n",
      "|    value_loss         | 1.06e-07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 298      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.91    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 6.88e-05 |\n",
      "|    std                | 1.63     |\n",
      "|    value_loss         | 7.6e-09  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 301      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.92    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 0.00024  |\n",
      "|    std                | 1.66     |\n",
      "|    value_loss         | 3.4e-08  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.01e+04  |\n",
      "|    total_cost         | 0         |\n",
      "|    total_reward       | 89.3      |\n",
      "|    total_reward_pct   | 0.893     |\n",
      "|    total_trades       | 524       |\n",
      "| time/                 |           |\n",
      "|    fps                | 303       |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 49        |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.94     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | -0.000668 |\n",
      "|    std                | 1.69      |\n",
      "|    value_loss         | 1.19e-07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 305      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.96    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 0.000221 |\n",
      "|    std                | 1.72     |\n",
      "|    value_loss         | 3.26e-08 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 306      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.98    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 1.79e-05 |\n",
      "|    std                | 1.75     |\n",
      "|    value_loss         | 4.42e-10 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.01e+04 |\n",
      "|    total_cost         | 0        |\n",
      "|    total_reward       | 51.6     |\n",
      "|    total_reward_pct   | 0.516    |\n",
      "|    total_trades       | 588      |\n",
      "| time/                 |          |\n",
      "|    fps                | 307      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 16500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2       |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 5.84e-05 |\n",
      "|    std                | 1.79     |\n",
      "|    value_loss         | 4.07e-09 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 308       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 55        |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.02     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | -0.000461 |\n",
      "|    std                | 1.82      |\n",
      "|    value_loss         | 4.75e-08  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 309      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.04    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 0.00259  |\n",
      "|    std                | 1.86     |\n",
      "|    value_loss         | 1.32e-06 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.97e+03  |\n",
      "|    total_cost         | 0         |\n",
      "|    total_reward       | -28.8     |\n",
      "|    total_reward_pct   | -0.288    |\n",
      "|    total_trades       | 569       |\n",
      "| time/                 |           |\n",
      "|    fps                | 310       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 57        |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.06     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | 9.47e-05  |\n",
      "|    std                | 1.89      |\n",
      "|    value_loss         | 9.52e-09  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 311       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 59        |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.08     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | -9.63e-06 |\n",
      "|    std                | 1.93      |\n",
      "|    value_loss         | 1.6e-08   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 313      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.09    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 1.52e-05 |\n",
      "|    std                | 1.97     |\n",
      "|    value_loss         | 7.82e-09 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.91e+03  |\n",
      "|    total_cost         | 0         |\n",
      "|    total_reward       | -85.3     |\n",
      "|    total_reward_pct   | -0.853    |\n",
      "|    total_trades       | 607       |\n",
      "| time/                 |           |\n",
      "|    fps                | 314       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 62        |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.11     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | -0.000394 |\n",
      "|    std                | 2         |\n",
      "|    value_loss         | 9.41e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 315       |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 63        |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.13     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | 0.000122  |\n",
      "|    std                | 2.04      |\n",
      "|    value_loss         | 1.03e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 316       |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 64        |\n",
      "|    total_timesteps    | 20500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.15     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | -0.000232 |\n",
      "|    std                | 2.09      |\n",
      "|    value_loss         | 2.31e-08  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+04    |\n",
      "|    total_cost         | 0        |\n",
      "|    total_reward       | 43.4     |\n",
      "|    total_reward_pct   | 0.434    |\n",
      "|    total_trades       | 639      |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.17    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 8.99e-05 |\n",
      "|    std                | 2.13     |\n",
      "|    value_loss         | 8.58e-09 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 318       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 67        |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.19     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | -4.48e-05 |\n",
      "|    std                | 2.17      |\n",
      "|    value_loss         | 3.06e-09  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.21    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -0.0002  |\n",
      "|    std                | 2.21     |\n",
      "|    value_loss         | 8.43e-09 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.91e+03 |\n",
      "|    total_cost         | 0        |\n",
      "|    total_reward       | -86.6    |\n",
      "|    total_reward_pct   | -0.866   |\n",
      "|    total_trades       | 609      |\n",
      "| time/                 |          |\n",
      "|    fps                | 317      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.23    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -0.00045 |\n",
      "|    std                | 2.25     |\n",
      "|    value_loss         | 4.47e-08 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 317       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 72        |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.25     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | -0.000156 |\n",
      "|    std                | 2.3       |\n",
      "|    value_loss         | 1.08e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 317       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 73        |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.27     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | 0.00012   |\n",
      "|    std                | 2.34      |\n",
      "|    value_loss         | 3.19e-09  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.91e+03  |\n",
      "|    total_cost         | 0         |\n",
      "|    total_reward       | -85       |\n",
      "|    total_reward_pct   | -0.85     |\n",
      "|    total_trades       | 674       |\n",
      "| time/                 |           |\n",
      "|    fps                | 318       |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 75        |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.29     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | 9.57e-05  |\n",
      "|    std                | 2.39      |\n",
      "|    value_loss         | 7.77e-09  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 320      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 24500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.31    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -0.00037 |\n",
      "|    std                | 2.44     |\n",
      "|    value_loss         | 4.94e-08 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 321      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.33    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 0.00161  |\n",
      "|    std                | 2.49     |\n",
      "|    value_loss         | 6.16e-07 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+04     |\n",
      "|    total_cost         | 0         |\n",
      "|    total_reward       | 18.6      |\n",
      "|    total_reward_pct   | 0.186     |\n",
      "|    total_trades       | 683       |\n",
      "| time/                 |           |\n",
      "|    fps                | 322       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 79        |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.35     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | 0.00103   |\n",
      "|    std                | 2.54      |\n",
      "|    value_loss         | 3.16e-07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 323      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.37    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 0.000393 |\n",
      "|    std                | 2.58     |\n",
      "|    value_loss         | 5.27e-08 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 324       |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 81        |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.38     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | -8.27e-06 |\n",
      "|    std                | 2.62      |\n",
      "|    value_loss         | 1.7e-09   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.01e+04 |\n",
      "|    total_cost         | 0        |\n",
      "|    total_reward       | 62.9     |\n",
      "|    total_reward_pct   | 0.629    |\n",
      "|    total_trades       | 673      |\n",
      "| time/                 |          |\n",
      "|    fps                | 325      |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 27000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.4     |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | 0.00077  |\n",
      "|    std                | 2.67     |\n",
      "|    value_loss         | 1.87e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 325      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.42    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 0.000524 |\n",
      "|    std                | 2.72     |\n",
      "|    value_loss         | 9.39e-08 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 326       |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 85        |\n",
      "|    total_timesteps    | 28000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.44     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | -0.000615 |\n",
      "|    std                | 2.78      |\n",
      "|    value_loss         | 8.42e-08  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.96e+03 |\n",
      "|    total_cost         | 0        |\n",
      "|    total_reward       | -35.2    |\n",
      "|    total_reward_pct   | -0.352   |\n",
      "|    total_trades       | 742      |\n",
      "| time/                 |          |\n",
      "|    fps                | 327      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.46    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 0.00117  |\n",
      "|    std                | 2.83     |\n",
      "|    value_loss         | 1.4e-07  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 327      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.48    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | -0.00073 |\n",
      "|    std                | 2.89     |\n",
      "|    value_loss         | 1.23e-07 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 328       |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 89        |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.5      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | 0.00166   |\n",
      "|    std                | 2.95      |\n",
      "|    value_loss         | 3.81e-07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.93e+03 |\n",
      "|    total_cost         | 0        |\n",
      "|    total_reward       | -70      |\n",
      "|    total_reward_pct   | -0.7     |\n",
      "|    total_trades       | 699      |\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.52    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | 0.000481 |\n",
      "|    std                | 3.01     |\n",
      "|    value_loss         | 4.65e-08 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 329       |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 92        |\n",
      "|    total_timesteps    | 30500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.54     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | -0.000225 |\n",
      "|    std                | 3.07      |\n",
      "|    value_loss         | 1.55e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 330       |\n",
      "|    iterations         | 6200      |\n",
      "|    time_elapsed       | 93        |\n",
      "|    total_timesteps    | 31000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.56     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6199      |\n",
      "|    policy_loss        | -0.000555 |\n",
      "|    std                | 3.13      |\n",
      "|    value_loss         | 8.53e-08  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.98e+03 |\n",
      "|    total_cost         | 0        |\n",
      "|    total_reward       | -17.2    |\n",
      "|    total_reward_pct   | -0.172   |\n",
      "|    total_trades       | 731      |\n",
      "| time/                 |          |\n",
      "|    fps                | 331      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 95       |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.58    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | 0.00066  |\n",
      "|    std                | 3.19     |\n",
      "|    value_loss         | 1.16e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 331      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.6     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | 0.000236 |\n",
      "|    std                | 3.26     |\n",
      "|    value_loss         | 2.04e-08 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 332       |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 97        |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.62     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | -0.000655 |\n",
      "|    std                | 3.32      |\n",
      "|    value_loss         | 7.65e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+04     |\n",
      "|    total_cost         | 0         |\n",
      "|    total_reward       | 14.9      |\n",
      "|    total_reward_pct   | 0.149     |\n",
      "|    total_trades       | 753       |\n",
      "| time/                 |           |\n",
      "|    fps                | 332       |\n",
      "|    iterations         | 6600      |\n",
      "|    time_elapsed       | 99        |\n",
      "|    total_timesteps    | 33000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.64     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6599      |\n",
      "|    policy_loss        | -0.000312 |\n",
      "|    std                | 3.39      |\n",
      "|    value_loss         | 2.46e-08  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 333      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.66    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | 0.000751 |\n",
      "|    std                | 3.45     |\n",
      "|    value_loss         | 1e-07    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 334      |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 101      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.68    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | 0.000863 |\n",
      "|    std                | 3.51     |\n",
      "|    value_loss         | 1.07e-07 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+04     |\n",
      "|    total_cost         | 0         |\n",
      "|    total_reward       | 16.4      |\n",
      "|    total_reward_pct   | 0.164     |\n",
      "|    total_trades       | 763       |\n",
      "| time/                 |           |\n",
      "|    fps                | 335       |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 102       |\n",
      "|    total_timesteps    | 34500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.7      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | -0.00629  |\n",
      "|    std                | 3.58      |\n",
      "|    value_loss         | 7.21e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 335       |\n",
      "|    iterations         | 7000      |\n",
      "|    time_elapsed       | 104       |\n",
      "|    total_timesteps    | 35000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.72     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | -0.00128  |\n",
      "|    std                | 3.66      |\n",
      "|    value_loss         | 5.77e-07  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 336       |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 105       |\n",
      "|    total_timesteps    | 35500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.74     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | -0.000517 |\n",
      "|    std                | 3.73      |\n",
      "|    value_loss         | 5.11e-08  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.96e+03 |\n",
      "|    total_cost         | 0        |\n",
      "|    total_reward       | -37.8    |\n",
      "|    total_reward_pct   | -0.378   |\n",
      "|    total_trades       | 765      |\n",
      "| time/                 |          |\n",
      "|    fps                | 336      |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 106      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.76    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | 0.00124  |\n",
      "|    std                | 3.81     |\n",
      "|    value_loss         | 2.83e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 337      |\n",
      "|    iterations         | 7300     |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 36500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.77    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 7299     |\n",
      "|    policy_loss        | 0.000164 |\n",
      "|    std                | 3.88     |\n",
      "|    value_loss         | 5.15e-09 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 337      |\n",
      "|    iterations         | 7400     |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 37000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.79    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 7399     |\n",
      "|    policy_loss        | 2.69e-05 |\n",
      "|    std                | 3.96     |\n",
      "|    value_loss         | 1.06e-08 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.01e+04  |\n",
      "|    total_cost         | 0         |\n",
      "|    total_reward       | 137       |\n",
      "|    total_reward_pct   | 1.37      |\n",
      "|    total_trades       | 775       |\n",
      "| time/                 |           |\n",
      "|    fps                | 338       |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 110       |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.81     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | -0.000931 |\n",
      "|    std                | 4.04      |\n",
      "|    value_loss         | 2.13e-07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 338      |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 112      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.83    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | 0.000261 |\n",
      "|    std                | 4.12     |\n",
      "|    value_loss         | 1.32e-08 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 339      |\n",
      "|    iterations         | 7700     |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 38500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.85    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 7699     |\n",
      "|    policy_loss        | 0.000928 |\n",
      "|    std                | 4.2      |\n",
      "|    value_loss         | 1.14e-07 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1e+04     |\n",
      "|    total_cost         | 0         |\n",
      "|    total_reward       | -2.51     |\n",
      "|    total_reward_pct   | -0.0251   |\n",
      "|    total_trades       | 831       |\n",
      "| time/                 |           |\n",
      "|    fps                | 339       |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 114       |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.87     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | -0.000224 |\n",
      "|    std                | 4.29      |\n",
      "|    value_loss         | 1.35e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 340       |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 116       |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.89     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | -0.000726 |\n",
      "|    std                | 4.37      |\n",
      "|    value_loss         | 2.06e-07  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 340       |\n",
      "|    iterations         | 8000      |\n",
      "|    time_elapsed       | 117       |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.91     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7999      |\n",
      "|    policy_loss        | -0.000283 |\n",
      "|    std                | 4.46      |\n",
      "|    value_loss         | 2.12e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.99e+03  |\n",
      "|    total_cost         | 0         |\n",
      "|    total_reward       | -9.95     |\n",
      "|    total_reward_pct   | -0.0995   |\n",
      "|    total_trades       | 805       |\n",
      "| time/                 |           |\n",
      "|    fps                | 340       |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 118       |\n",
      "|    total_timesteps    | 40500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.93     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8099      |\n",
      "|    policy_loss        | -0.000346 |\n",
      "|    std                | 4.55      |\n",
      "|    value_loss         | 2.38e-08  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 340      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.95    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | 0.000711 |\n",
      "|    std                | 4.63     |\n",
      "|    value_loss         | 6.13e-08 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 340      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.97    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | 0.000113 |\n",
      "|    std                | 4.72     |\n",
      "|    value_loss         | 3.49e-09 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.94e+03 |\n",
      "|    total_cost         | 0        |\n",
      "|    total_reward       | -60.5    |\n",
      "|    total_reward_pct   | -0.605   |\n",
      "|    total_trades       | 807      |\n",
      "| time/                 |          |\n",
      "|    fps                | 341      |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 123      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.99    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | -0.00418 |\n",
      "|    std                | 4.81     |\n",
      "|    value_loss         | 2.54e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 341      |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 124      |\n",
      "|    total_timesteps    | 42500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.01    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | -0.00217 |\n",
      "|    std                | 4.91     |\n",
      "|    value_loss         | 3.3e-07  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 341      |\n",
      "|    iterations         | 8600     |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 43000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.03    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 8599     |\n",
      "|    policy_loss        | -0.00065 |\n",
      "|    std                | 5.01     |\n",
      "|    value_loss         | 6.46e-08 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.87e+03  |\n",
      "|    total_cost         | 0         |\n",
      "|    total_reward       | -132      |\n",
      "|    total_reward_pct   | -1.32     |\n",
      "|    total_trades       | 840       |\n",
      "| time/                 |           |\n",
      "|    fps                | 342       |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 127       |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.05     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | -0.000333 |\n",
      "|    std                | 5.11      |\n",
      "|    value_loss         | 1.8e-08   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 342       |\n",
      "|    iterations         | 8800      |\n",
      "|    time_elapsed       | 128       |\n",
      "|    total_timesteps    | 44000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.07     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8799      |\n",
      "|    policy_loss        | -0.000394 |\n",
      "|    std                | 5.21      |\n",
      "|    value_loss         | 3.49e-08  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 8900     |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 44500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.09    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 8899     |\n",
      "|    policy_loss        | 0.000319 |\n",
      "|    std                | 5.31     |\n",
      "|    value_loss         | 2.72e-08 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+04    |\n",
      "|    total_cost         | 0        |\n",
      "|    total_reward       | 29.8     |\n",
      "|    total_reward_pct   | 0.298    |\n",
      "|    total_trades       | 824      |\n",
      "| time/                 |          |\n",
      "|    fps                | 342      |\n",
      "|    iterations         | 9000     |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.11    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 8999     |\n",
      "|    policy_loss        | 0.00038  |\n",
      "|    std                | 5.42     |\n",
      "|    value_loss         | 2.46e-08 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 343       |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 132       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.13     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | -2.38e-05 |\n",
      "|    std                | 5.53      |\n",
      "|    value_loss         | 1.81e-09  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 343      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 133      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.15    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | 0.000432 |\n",
      "|    std                | 5.64     |\n",
      "|    value_loss         | 2.82e-08 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.01e+04 |\n",
      "|    total_cost         | 0        |\n",
      "|    total_reward       | 54.3     |\n",
      "|    total_reward_pct   | 0.543    |\n",
      "|    total_trades       | 853      |\n",
      "| time/                 |          |\n",
      "|    fps                | 343      |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 46500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.17    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | 0.00258  |\n",
      "|    std                | 5.75     |\n",
      "|    value_loss         | 7.02e-07 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 343       |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 136       |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.19     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | 0.000921  |\n",
      "|    std                | 5.86      |\n",
      "|    value_loss         | 1.09e-07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 344      |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 138      |\n",
      "|    total_timesteps    | 47500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.21    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 0.00024  |\n",
      "|    std                | 5.98     |\n",
      "|    value_loss         | 8.73e-09 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.96e+03 |\n",
      "|    total_cost         | 0        |\n",
      "|    total_reward       | -40.3    |\n",
      "|    total_reward_pct   | -0.403   |\n",
      "|    total_trades       | 863      |\n",
      "| time/                 |          |\n",
      "|    fps                | 344      |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.22    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | 0.00113  |\n",
      "|    std                | 6.06     |\n",
      "|    value_loss         | 1.59e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 344      |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 140      |\n",
      "|    total_timesteps    | 48500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.23    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | 0.000204 |\n",
      "|    std                | 6.14     |\n",
      "|    value_loss         | 1.62e-08 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 344       |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 142       |\n",
      "|    total_timesteps    | 49000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.25     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | -0.000122 |\n",
      "|    std                | 6.24      |\n",
      "|    value_loss         | 1.57e-09  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.9e+03  |\n",
      "|    total_cost         | 0        |\n",
      "|    total_reward       | -103     |\n",
      "|    total_reward_pct   | -1.03    |\n",
      "|    total_trades       | 847      |\n",
      "| time/                 |          |\n",
      "|    fps                | 345      |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 143      |\n",
      "|    total_timesteps    | 49500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.27    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | -0.00186 |\n",
      "|    std                | 6.35     |\n",
      "|    value_loss         | 5.5e-07  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 345      |\n",
      "|    iterations         | 10000    |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.29    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0002   |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | 0.0028   |\n",
      "|    std                | 6.48     |\n",
      "|    value_loss         | 7.11e-07 |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "agent = DRLAgent(env = env_train)\n",
    "\n",
    "A2C_PARAMS = {\"n_steps\": 5, \"ent_coef\": 0.005, \"learning_rate\": 0.0002}\n",
    "model_a2c = agent.get_model(model_name=\"a2c\",model_kwargs = A2C_PARAMS)\n",
    "\n",
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                                tb_log_name='a2c',\n",
    "                                total_timesteps=50000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9upN8FI2r_X1"
   },
   "source": [
    "### Model 2: DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gUFJlHsi-Ka-",
    "outputId": "1b7db70f-f740-401c-ab55-a567b4235e18"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.005, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo/ppo_19\n",
      "----------------------------------\n",
      "| environment/        |          |\n",
      "|    portfolio_value  | 1.01e+04 |\n",
      "|    total_cost       | 0        |\n",
      "|    total_reward     | 67.2     |\n",
      "|    total_reward_pct | 0.672    |\n",
      "|    total_trades     | 306      |\n",
      "| time/               |          |\n",
      "|    fps              | 615      |\n",
      "|    iterations       | 1        |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 2048     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 9.97e+03     |\n",
      "|    total_cost           | 0            |\n",
      "|    total_reward         | -33.8        |\n",
      "|    total_reward_pct     | -0.338       |\n",
      "|    total_trades         | 314          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 546          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031306096 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | -4.32        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00574     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.000327    |\n",
      "|    std                  | 0.995        |\n",
      "|    value_loss           | 0.0151       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 9.92e+03     |\n",
      "|    total_cost           | 0            |\n",
      "|    total_reward         | -80.5        |\n",
      "|    total_reward_pct     | -0.805       |\n",
      "|    total_trades         | 310          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 532          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075210603 |\n",
      "|    clip_fraction        | 0.0239       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -1.86        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00259     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00201     |\n",
      "|    std                  | 0.991        |\n",
      "|    value_loss           | 0.00193      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.01e+04     |\n",
      "|    total_cost           | 0            |\n",
      "|    total_reward         | 50.7         |\n",
      "|    total_reward_pct     | 0.507        |\n",
      "|    total_trades         | 275          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 528          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020819295 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -0.198       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00888     |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.000463    |\n",
      "|    std                  | 0.988        |\n",
      "|    value_loss           | 0.00134      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 9.97e+03     |\n",
      "|    total_cost           | 0            |\n",
      "|    total_reward         | -29.1        |\n",
      "|    total_reward_pct     | -0.291       |\n",
      "|    total_trades         | 324          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 527          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017760653 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -0.583       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00139     |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.000202    |\n",
      "|    std                  | 0.985        |\n",
      "|    value_loss           | 0.000667     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1e+04       |\n",
      "|    total_cost           | 0           |\n",
      "|    total_reward         | 22.5        |\n",
      "|    total_reward_pct     | 0.225       |\n",
      "|    total_trades         | 304         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 531         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001238119 |\n",
      "|    clip_fraction        | 0.000391    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | -0.33       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00101     |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.000306   |\n",
      "|    std                  | 0.982       |\n",
      "|    value_loss           | 0.000408    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1.01e+04    |\n",
      "|    total_cost           | 0           |\n",
      "|    total_reward         | 108         |\n",
      "|    total_reward_pct     | 1.08        |\n",
      "|    total_trades         | 291         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 535         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005113562 |\n",
      "|    clip_fraction        | 0.0424      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | -0.462      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0163     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00327    |\n",
      "|    std                  | 0.982       |\n",
      "|    value_loss           | 0.000487    |\n",
      "-----------------------------------------\n",
      "--------------------------------------------\n",
      "| environment/            |                |\n",
      "|    portfolio_value      | 9.98e+03       |\n",
      "|    total_cost           | 0              |\n",
      "|    total_reward         | -24.2          |\n",
      "|    total_reward_pct     | -0.242         |\n",
      "|    total_trades         | 314            |\n",
      "| time/                   |                |\n",
      "|    fps                  | 538            |\n",
      "|    iterations           | 8              |\n",
      "|    time_elapsed         | 30             |\n",
      "|    total_timesteps      | 16384          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -0.00037503787 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.4           |\n",
      "|    explained_variance   | -0.533         |\n",
      "|    learning_rate        | 0.0001         |\n",
      "|    loss                 | -0.00845       |\n",
      "|    n_updates            | 70             |\n",
      "|    policy_gradient_loss | -0.000365      |\n",
      "|    std                  | 0.984          |\n",
      "|    value_loss           | 0.000195       |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1e+04        |\n",
      "|    total_cost           | 0            |\n",
      "|    total_reward         | 28.7         |\n",
      "|    total_reward_pct     | 0.287        |\n",
      "|    total_trades         | 309          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 540          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 34           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061839595 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | -0.381       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0179      |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0013      |\n",
      "|    std                  | 0.982        |\n",
      "|    value_loss           | 0.000215     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1e+04        |\n",
      "|    total_cost           | 0            |\n",
      "|    total_reward         | 0.15         |\n",
      "|    total_reward_pct     | 0.0015       |\n",
      "|    total_trades         | 303          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 541          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 37           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012829165 |\n",
      "|    clip_fraction        | 0.00313      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | -1.49        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00282     |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.0011      |\n",
      "|    std                  | 0.98         |\n",
      "|    value_loss           | 0.000156     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.01e+04     |\n",
      "|    total_cost           | 0            |\n",
      "|    total_reward         | 99.7         |\n",
      "|    total_reward_pct     | 0.997        |\n",
      "|    total_trades         | 314          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 542          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034252163 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | -1.08        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00127     |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00179     |\n",
      "|    std                  | 0.981        |\n",
      "|    value_loss           | 8.66e-05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1e+04        |\n",
      "|    total_cost           | 0            |\n",
      "|    total_reward         | -2.59        |\n",
      "|    total_reward_pct     | -0.0259      |\n",
      "|    total_trades         | 303          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 544          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 45           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038262894 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | -0.676       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0122      |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00132     |\n",
      "|    std                  | 0.983        |\n",
      "|    value_loss           | 9.01e-05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 9.97e+03     |\n",
      "|    total_cost           | 0            |\n",
      "|    total_reward         | -26.7        |\n",
      "|    total_reward_pct     | -0.267       |\n",
      "|    total_trades         | 305          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 544          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040049795 |\n",
      "|    clip_fraction        | 0.0377       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | -2.71        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0223      |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00364     |\n",
      "|    std                  | 0.982        |\n",
      "|    value_loss           | 6.5e-05      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1e+04        |\n",
      "|    total_cost           | 0            |\n",
      "|    total_reward         | 4.67         |\n",
      "|    total_reward_pct     | 0.0467       |\n",
      "|    total_trades         | 278          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 545          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 52           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007302112 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | -1.8         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00369     |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.000205    |\n",
      "|    std                  | 0.979        |\n",
      "|    value_loss           | 3.49e-05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 9.98e+03     |\n",
      "|    total_cost           | 0            |\n",
      "|    total_reward         | -25          |\n",
      "|    total_reward_pct     | -0.25        |\n",
      "|    total_trades         | 322          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 545          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 56           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007244171 |\n",
      "|    clip_fraction        | 0.000391     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | -2.11        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00881     |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.000437    |\n",
      "|    std                  | 0.985        |\n",
      "|    value_loss           | 4.47e-05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| environment/            |               |\n",
      "|    portfolio_value      | 9.99e+03      |\n",
      "|    total_cost           | 0             |\n",
      "|    total_reward         | -5.55         |\n",
      "|    total_reward_pct     | -0.0555       |\n",
      "|    total_trades         | 343           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 545           |\n",
      "|    iterations           | 16            |\n",
      "|    time_elapsed         | 60            |\n",
      "|    total_timesteps      | 32768         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00067417487 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.41         |\n",
      "|    explained_variance   | -2.46         |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | -0.00374      |\n",
      "|    n_updates            | 150           |\n",
      "|    policy_gradient_loss | -4.44e-05     |\n",
      "|    std                  | 0.989         |\n",
      "|    value_loss           | 2.07e-05      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 1e+04       |\n",
      "|    total_cost           | 0           |\n",
      "|    total_reward         | 47.5        |\n",
      "|    total_reward_pct     | 0.475       |\n",
      "|    total_trades         | 321         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 546         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003139696 |\n",
      "|    clip_fraction        | 0.00176     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | -1.54       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.012      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.000423   |\n",
      "|    std                  | 0.992       |\n",
      "|    value_loss           | 1.95e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 9.98e+03     |\n",
      "|    total_cost           | 0            |\n",
      "|    total_reward         | -21.4        |\n",
      "|    total_reward_pct     | -0.214       |\n",
      "|    total_trades         | 323          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 545          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 67           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010196331 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -5.1         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00676     |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.000763    |\n",
      "|    std                  | 0.992        |\n",
      "|    value_loss           | 1.8e-05      |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| environment/            |                |\n",
      "|    portfolio_value      | 1e+04          |\n",
      "|    total_cost           | 0              |\n",
      "|    total_reward         | 27.8           |\n",
      "|    total_reward_pct     | 0.278          |\n",
      "|    total_trades         | 299            |\n",
      "| time/                   |                |\n",
      "|    fps                  | 542            |\n",
      "|    iterations           | 19             |\n",
      "|    time_elapsed         | 71             |\n",
      "|    total_timesteps      | 38912          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -0.00013938936 |\n",
      "|    clip_fraction        | 0.00376        |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -1.41          |\n",
      "|    explained_variance   | -3.41          |\n",
      "|    learning_rate        | 0.0001         |\n",
      "|    loss                 | -0.00427       |\n",
      "|    n_updates            | 180            |\n",
      "|    policy_gradient_loss | -3.46e-05      |\n",
      "|    std                  | 0.992          |\n",
      "|    value_loss           | 9.31e-06       |\n",
      "--------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.99e+03    |\n",
      "|    total_cost           | 0           |\n",
      "|    total_reward         | -14.6       |\n",
      "|    total_reward_pct     | -0.146      |\n",
      "|    total_trades         | 319         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 540         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004154401 |\n",
      "|    clip_fraction        | 0.0384      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | -2.46       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00874    |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00161    |\n",
      "|    std                  | 0.993       |\n",
      "|    value_loss           | 9.41e-06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1e+04        |\n",
      "|    total_cost           | 0            |\n",
      "|    total_reward         | 36.1         |\n",
      "|    total_reward_pct     | 0.361        |\n",
      "|    total_trades         | 311          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 539          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 79           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033283136 |\n",
      "|    clip_fraction        | 0.031        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -5.5         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.01        |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.0015      |\n",
      "|    std                  | 0.996        |\n",
      "|    value_loss           | 7.39e-06     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.96e+03    |\n",
      "|    total_cost           | 0           |\n",
      "|    total_reward         | -40.6       |\n",
      "|    total_reward_pct     | -0.406      |\n",
      "|    total_trades         | 293         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 538         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003436775 |\n",
      "|    clip_fraction        | 0.0106      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | -2.47       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00604     |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0014     |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 3.32e-06    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| environment/            |               |\n",
      "|    portfolio_value      | 1e+04         |\n",
      "|    total_cost           | 0             |\n",
      "|    total_reward         | 32            |\n",
      "|    total_reward_pct     | 0.32          |\n",
      "|    total_trades         | 274           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 537           |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 87            |\n",
      "|    total_timesteps      | 47104         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0008704916 |\n",
      "|    clip_fraction        | 0.0398        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.42         |\n",
      "|    explained_variance   | -2.89         |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | -0.0217       |\n",
      "|    n_updates            | 220           |\n",
      "|    policy_gradient_loss | -0.00334      |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 4.41e-06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| environment/            |               |\n",
      "|    portfolio_value      | 1.01e+04      |\n",
      "|    total_cost           | 0             |\n",
      "|    total_reward         | 59.1          |\n",
      "|    total_reward_pct     | 0.591         |\n",
      "|    total_trades         | 295           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 537           |\n",
      "|    iterations           | 24            |\n",
      "|    time_elapsed         | 91            |\n",
      "|    total_timesteps      | 49152         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013521142 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.42         |\n",
      "|    explained_variance   | -2.67         |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | -0.00766      |\n",
      "|    n_updates            | 230           |\n",
      "|    policy_gradient_loss | -1.67e-05     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 1.45e-06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.01e+04     |\n",
      "|    total_cost           | 0            |\n",
      "|    total_reward         | 64.4         |\n",
      "|    total_reward_pct     | 0.644        |\n",
      "|    total_trades         | 325          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 536          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 95           |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026988508 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | -1.38        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.000205    |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.000496    |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 1.11e-06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| environment/            |               |\n",
      "|    portfolio_value      | 9.93e+03      |\n",
      "|    total_cost           | 0             |\n",
      "|    total_reward         | -65.6         |\n",
      "|    total_reward_pct     | -0.656        |\n",
      "|    total_trades         | 327           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 535           |\n",
      "|    iterations           | 26            |\n",
      "|    time_elapsed         | 99            |\n",
      "|    total_timesteps      | 53248         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00060383667 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.42         |\n",
      "|    explained_variance   | -2.06         |\n",
      "|    learning_rate        | 0.0001        |\n",
      "|    loss                 | -0.00914      |\n",
      "|    n_updates            | 250           |\n",
      "|    policy_gradient_loss | -0.000252     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 1.64e-06      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| environment/            |             |\n",
      "|    portfolio_value      | 9.99e+03    |\n",
      "|    total_cost           | 0           |\n",
      "|    total_reward         | -8.88       |\n",
      "|    total_reward_pct     | -0.0888     |\n",
      "|    total_trades         | 297         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 535         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005823175 |\n",
      "|    clip_fraction        | 0.00479     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | -1.45       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.000633    |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.000664   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 7.07e-07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 9.92e+03     |\n",
      "|    total_cost           | 0            |\n",
      "|    total_reward         | -84.3        |\n",
      "|    total_reward_pct     | -0.843       |\n",
      "|    total_trades         | 271          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 534          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 107          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050603296 |\n",
      "|    clip_fraction        | 0.0545       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.43        |\n",
      "|    explained_variance   | -0.758       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0121      |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00326     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 7.31e-07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 1.01e+04     |\n",
      "|    total_cost           | 0            |\n",
      "|    total_reward         | 76.3         |\n",
      "|    total_reward_pct     | 0.763        |\n",
      "|    total_trades         | 270          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 534          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 111          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014586765 |\n",
      "|    clip_fraction        | 0.0063       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.43        |\n",
      "|    explained_variance   | -1.31        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00617     |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.000599    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 6.97e-07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| environment/            |              |\n",
      "|    portfolio_value      | 9.98e+03     |\n",
      "|    total_cost           | 0            |\n",
      "|    total_reward         | -17.3        |\n",
      "|    total_reward_pct     | -0.173       |\n",
      "|    total_trades         | 241          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 533          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 115          |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037492502 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.43        |\n",
      "|    explained_variance   | -1.15        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0121      |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00104     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 6.61e-07     |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.005,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n",
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                            tb_log_name='ppo',\n",
    "                            total_timesteps=60000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Successfully added technical indicators\n",
      "    0\n",
      "0   0\n",
      "1  -1\n",
      "2   0\n",
      "3   1\n",
      "4   0\n",
      "5   0\n",
      "6  -1\n",
      "7   0\n",
      "8   0\n",
      "9   0\n",
      "10  0\n",
      "11  0\n",
      "12  0\n",
      "13  0\n",
      "14  0\n",
      "15  0\n",
      "16  0\n",
      "17  0\n",
      "18  0\n",
      "10004.349999999999\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "trade = pd.read_csv('testing.csv',names=col_names)\n",
    "trade['tic']='IBM'\n",
    "base=datetime.strptime(config.START_TRADE_DATE,\"%Y-%m-%d\")\n",
    "date=[base + timedelta(days=x)for x in range(len(trade))]\n",
    "trade['date']=date\n",
    "trade=fe.preprocess_data(trade)\n",
    "\n",
    "e_trade_gym = StockTradingEnv(df = trade, **env_kwargs)\n",
    "\n",
    "max_profit=0\n",
    "actions=None\n",
    "negative_trade=0\n",
    "for _ in range(10):\n",
    "    df_account_value, df_actions = DRLAgent.DRL_prediction(model=trained_ppo,environment = e_trade_gym)\n",
    "    final_profit=df_account_value['account_value'].iloc[-1]\n",
    "    if final_profit<10000:\n",
    "        negative_trade+=1\n",
    "    if final_profit>max_profit:\n",
    "        max_profit=final_profit\n",
    "        actions=pd.DataFrame(np.array(df_actions['actions'],dtype='int'))\n",
    "\n",
    "print(actions)\n",
    "print(max_profit)\n",
    "print(negative_trade)\n",
    "actions.to_csv(\"action.csv\",index=False,header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Y9CM5DeIr9GC",
    "9upN8FI2r_X1",
    "CiBG2ZknsG73"
   ],
   "include_colab_link": true,
   "name": "FinRL_single_stock_trading.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}